{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdyipqESTVPxgWvAe0Upcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Video_Dubber/blob/main/TTS_Gemini_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sub"
      ],
      "metadata": {
        "id": "BH_qojhxSJC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download sub from https://downsub.com/"
      ],
      "metadata": {
        "id": "3fKH6I7MSUHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improveing sub"
      ],
      "metadata": {
        "id": "EdDd84SBQMuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BMjxhE2bJKz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871bf769-2766-48fd-e4bd-ba44315f5288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysrt\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m102.4/104.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from pysrt) (5.2.0)\n",
            "Building wheels for collected packages: pysrt\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=5f763226bfb108d755d604e2093b08e6b59eefb793790750938d847ea3c7a84d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/b2/df/ea10959920533975b4a74a25a35e6d79655b63f3006611a99f\n",
            "Successfully built pysrt\n",
            "Installing collected packages: pysrt\n",
            "Successfully installed pysrt-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pysrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "from datetime import timedelta\n",
        "\n",
        "def to_timedelta(srt_time):\n",
        "    return timedelta(\n",
        "        hours=srt_time.hours,\n",
        "        minutes=srt_time.minutes,\n",
        "        seconds=srt_time.seconds,\n",
        "        milliseconds=srt_time.milliseconds,\n",
        "    )\n",
        "\n",
        "def is_noise_line(text):\n",
        "    stripped = text.strip()\n",
        "    return stripped.startswith('[') and stripped.endswith(']')\n",
        "\n",
        "def merge_close_subtitles(subs, threshold_ms=100):\n",
        "    merged_subs = pysrt.SubRipFile()\n",
        "    i = 0\n",
        "    threshold = timedelta(milliseconds=threshold_ms)\n",
        "\n",
        "    # Remove \"[...]\" noise lines before merging\n",
        "    filtered_subs = [sub for sub in subs if not is_noise_line(sub.text)]\n",
        "\n",
        "    while i < len(filtered_subs):\n",
        "        current = filtered_subs[i]\n",
        "        text = current.text\n",
        "        start_time = current.start\n",
        "        end_time = current.end\n",
        "\n",
        "        while (\n",
        "            i + 1 < len(filtered_subs) and\n",
        "            to_timedelta(filtered_subs[i + 1].start) - to_timedelta(end_time) <= threshold\n",
        "        ):\n",
        "            i += 1\n",
        "            text += ' ' + filtered_subs[i].text\n",
        "            end_time = filtered_subs[i].end\n",
        "\n",
        "        # Only include if there are at least 4 words\n",
        "        if len(text.strip().split()) >= 4:\n",
        "            merged_subs.append(pysrt.SubRipItem(\n",
        "                index=len(merged_subs) + 1,\n",
        "                start=start_time,\n",
        "                end=end_time,\n",
        "                text=text.strip()\n",
        "            ))\n",
        "        i += 1\n",
        "\n",
        "    return merged_subs\n"
      ],
      "metadata": {
        "id": "DWWbkXGLJ-JE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "from datetime import timedelta\n",
        "\n",
        "def to_timedelta(srt_time):\n",
        "    return timedelta(\n",
        "        hours=srt_time.hours,\n",
        "        minutes=srt_time.minutes,\n",
        "        seconds=srt_time.seconds,\n",
        "        milliseconds=srt_time.milliseconds,\n",
        "    )\n",
        "\n",
        "def is_noise_line(text):\n",
        "    stripped = text.strip()\n",
        "    return stripped.startswith('[') and stripped.endswith(']')\n",
        "\n",
        "def merge_close_subtitles(subs, threshold_ms=100, max_duration_s=20):\n",
        "    merged_subs = pysrt.SubRipFile()\n",
        "    i = 0\n",
        "    threshold = timedelta(milliseconds=threshold_ms)\n",
        "    max_duration = timedelta(seconds=max_duration_s)\n",
        "\n",
        "    # Remove \"[...]\" noise lines before merging\n",
        "    filtered_subs = [sub for sub in subs if not is_noise_line(sub.text)]\n",
        "\n",
        "    while i < len(filtered_subs):\n",
        "        current = filtered_subs[i]\n",
        "        text = current.text\n",
        "        start_time = current.start\n",
        "        end_time = current.end\n",
        "        original_duration = to_timedelta(end_time) - to_timedelta(start_time)\n",
        "\n",
        "        j = i + 1\n",
        "        while j < len(filtered_subs):\n",
        "            next_sub = filtered_subs[j]\n",
        "            gap = to_timedelta(next_sub.start) - to_timedelta(end_time)\n",
        "            new_end_time = next_sub.end\n",
        "            merged_duration = to_timedelta(new_end_time) - to_timedelta(start_time)\n",
        "\n",
        "            if gap <= threshold and merged_duration <= max_duration and merged_duration <= original_duration + max_duration:\n",
        "                text += ' ' + next_sub.text\n",
        "                end_time = new_end_time\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # Only include if there are at least 3 words\n",
        "        if len(text.strip().split()) >= 3:\n",
        "            merged_subs.append(pysrt.SubRipItem(\n",
        "                index=len(merged_subs) + 1,\n",
        "                start=start_time,\n",
        "                end=end_time,\n",
        "                text=text.strip()\n",
        "            ))\n",
        "\n",
        "        i = j  # move to next non-merged subtitle\n",
        "\n",
        "    return merged_subs\n"
      ],
      "metadata": {
        "id": "fY57SsadIGR_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load subtitle from string\n",
        "subs = pysrt.from_string(\"\"\"1\n",
        "00:00:09,040 --> 00:00:10,240\n",
        "guys greetings\n",
        "\n",
        "2\n",
        "00:00:10,240 --> 00:00:13,440\n",
        "from slovakia listen everyone told us\n",
        "\n",
        "3\n",
        "00:00:13,440 --> 00:00:14,960\n",
        "not to come to this place\n",
        "\n",
        "4\n",
        "00:00:14,960 --> 00:00:17,039\n",
        "they said we get robbed we get beaten we\n",
        "\n",
        "5\n",
        "00:00:17,039 --> 00:00:18,560\n",
        "definitely lose our camera\n",
        "\n",
        "6\n",
        "00:00:18,560 --> 00:00:39,00\n",
        "[Music]\n",
        "\n",
        "7\n",
        "00:00:39,680 --> 00:00:43,440\n",
        "my money i'm getting mugged by seven\n",
        "\n",
        "8\n",
        "00:00:43,440 --> 00:00:44,399\n",
        "year olds\n",
        "\n",
        "9\n",
        "00:00:44,399 --> 00:00:46,960\n",
        "in 1970s there was a big gypsy village\n",
        "\n",
        "10\n",
        "00:00:46,960 --> 00:00:48,559\n",
        "here big romani village\n",
        "\n",
        "11\n",
        "00:01:04,000 --> 00:01:07,040\n",
        "well over time the local\n",
        "\n",
        "12\n",
        "00:01:07,040 --> 00:01:10,479\n",
        "slovakian people you could say moved out\n",
        "\n",
        "13\n",
        "00:01:10,479 --> 00:01:13,920\n",
        "and this is what became of lunic 9.\n",
        "\"\"\")\n",
        "\n",
        "# Merge with a 100ms gap tolerance\n",
        "merged_subs = merge_close_subtitles(subs, threshold_ms=100)\n"
      ],
      "metadata": {
        "id": "J-4JEF7nKbBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in merged_subs:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6_fbp1xKBOK",
        "outputId": "2e9fd7cc-e6d6-4147-bf6a-f5a7434162ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "00:00:09,040 --> 00:00:18,560\n",
            "guys greetings from slovakia listen everyone told us not to come to this place they said we get robbed we get beaten we definitely lose our camera\n",
            "\n",
            "2\n",
            "00:00:39,680 --> 00:00:48,559\n",
            "my money i'm getting mugged by seven year olds in 1970s there was a big gypsy village here big romani village\n",
            "\n",
            "3\n",
            "00:01:04,000 --> 00:01:13,920\n",
            "well over time the local slovakian people you could say moved out and this is what became of lunic 9.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_close_subtitles(subs, threshold_ms=100, max_duration_s=20)"
      ],
      "metadata": {
        "id": "16qKrdl_KsXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "\n",
        "# Load an existing .srt file\n",
        "subs = pysrt.open('Chernobyl_Zone.srt', encoding='utf-8')\n",
        "\n",
        "# Merge with a 100ms gap tolerance\n",
        "merged_subs = merge_close_subtitles(subs, threshold_ms=100, max_duration_s=15)\n",
        "\n",
        "# Save to a new file\n",
        "merged_subs.save('merged_Chernobyl_Zone.srt', encoding='utf-8')"
      ],
      "metadata": {
        "id": "Jht4Y4fXK_jP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "CN7KqbQwQSVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "translate by https://chatgpt.com/g/g-SVxuCE6HY-subtitle-translato or the below"
      ],
      "metadata": {
        "id": "fxnBkXGSSe7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gemini-srt-translator"
      ],
      "metadata": {
        "id": "RnbH-0IOQS1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gemini_srt_translator as gst\n",
        "\n",
        "gst.gemini_api_key = \"AIzaSyD-fWQVGebMwTXKo2efj8JnlC39IUaID5U\"\n",
        "gst.target_language = \"Persian\"\n",
        "gst.input_file = \"/content/merged_output (1).srt\"\n",
        "\n",
        "gst.translate()"
      ],
      "metadata": {
        "id": "w-mv57nHQUQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjoXG_5WSq6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text to speeach"
      ],
      "metadata": {
        "id": "m2XqYiWPkUCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stretch_audio_to_fit(input_wav, output_wav, target_duration_ms):\n",
        "    \"\"\"Adjusts audio speed using FFmpeg to match a target duration.\"\"\"\n",
        "    original = AudioSegment.from_wav(input_wav)\n",
        "    original_duration = len(original)\n",
        "    speed_factor = original_duration / target_duration_ms\n",
        "\n",
        "    # Clamp speed factor to range for quality\n",
        "    speed_factor = max(0.85, min(speed_factor, 1.5))\n",
        "\n",
        "    if abs(speed_factor - 1.0) < 0.01:\n",
        "        os.rename(input_wav, output_wav)\n",
        "        return\n",
        "\n",
        "    print(f\"⏩ Stretching audio: {input_wav} -> {output_wav} | Speed factor: {speed_factor:.2f}\")\n",
        "\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"ffmpeg\", \"-y\", \"-loglevel\", \"error\",\n",
        "                \"-i\", input_wav,\n",
        "                \"-filter:a\", f\"atempo={speed_factor}\",\n",
        "                output_wav\n",
        "            ],\n",
        "            check=True\n",
        "        )\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"❌ FFmpeg failed while processing: {input_wav}\")"
      ],
      "metadata": {
        "id": "EvM1tcdU05ND"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To run this code you need to install the following dependencies:\n",
        "# pip install google-genai\n",
        "\n",
        "import base64\n",
        "import mimetypes\n",
        "import os\n",
        "import re\n",
        "import struct\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "def save_binary_file(file_name, data):\n",
        "    f = open(file_name, \"wb\")\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print(f\"File saved to: {file_name}\")\n",
        "\n",
        "\n",
        "def generate(api_key: str, text: str):\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    model = \"gemini-2.5-flash-preview-tts\"\n",
        "    #instruction = \"Read aloud in a warm, documentary-style tone, at a fast pace—faster than normal speech—while keeping clarity and expression: \\n\\n\"\n",
        "    instruction = \"Read aloud in a warm, documentary-style tone, slightly faster than a natural pace—while keeping clarity and expression: \\n\\n\"\n",
        "    full_text = instruction + text\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=full_text),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        response_modalities=[\"audio\"],\n",
        "        speech_config=types.SpeechConfig(\n",
        "            voice_config=types.VoiceConfig(\n",
        "                prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "                    voice_name=\"Charon\"\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    file_index = 0\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        if (\n",
        "            chunk.candidates is None\n",
        "            or chunk.candidates[0].content is None\n",
        "            or chunk.candidates[0].content.parts is None\n",
        "        ):\n",
        "            continue\n",
        "        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
        "            file_name = f\"generated_audio_{file_index}\"\n",
        "            file_index += 1\n",
        "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
        "            data_buffer = inline_data.data\n",
        "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
        "            if file_extension is None:\n",
        "                file_extension = \".wav\"\n",
        "                data_buffer = convert_to_wav(inline_data.data, inline_data.mime_type)\n",
        "            save_binary_file(f\"{file_name}{file_extension}\", data_buffer)\n",
        "        else:\n",
        "            print(chunk.text)\n",
        "\n",
        "\n",
        "def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:\n",
        "    parameters = parse_audio_mime_type(mime_type)\n",
        "    bits_per_sample = parameters[\"bits_per_sample\"]\n",
        "    sample_rate = parameters[\"rate\"]\n",
        "    num_channels = 1\n",
        "    data_size = len(audio_data)\n",
        "    bytes_per_sample = bits_per_sample // 8\n",
        "    block_align = num_channels * bytes_per_sample\n",
        "    byte_rate = sample_rate * block_align\n",
        "    chunk_size = 36 + data_size\n",
        "\n",
        "    header = struct.pack(\n",
        "        \"<4sI4s4sIHHIIHH4sI\",\n",
        "        b\"RIFF\", chunk_size, b\"WAVE\", b\"fmt \", 16, 1, num_channels,\n",
        "        sample_rate, byte_rate, block_align, bits_per_sample, b\"data\", data_size\n",
        "    )\n",
        "    return header + audio_data\n",
        "\n",
        "\n",
        "def parse_audio_mime_type(mime_type: str) -> dict[str, int | None]:\n",
        "    bits_per_sample = 16\n",
        "    rate = 24000\n",
        "\n",
        "    parts = mime_type.split(\";\")\n",
        "    for param in parts:\n",
        "        param = param.strip()\n",
        "        if param.lower().startswith(\"rate=\"):\n",
        "            try:\n",
        "                rate_str = param.split(\"=\", 1)[1]\n",
        "                rate = int(rate_str)\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "        elif param.startswith(\"audio/L\"):\n",
        "            try:\n",
        "                bits_per_sample = int(param.split(\"L\", 1)[1])\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "    return {\"bits_per_sample\": bits_per_sample, \"rate\": rate}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VP5N-VGqkC3B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_api_key = \"\"\n",
        "example_text = \"سلام بچه‌ها از اسلواکی بهتون سلام می‌کنم. ببینید، همه بهمون گفتن نیاید اینجا. گفتن اینجا دزدیه، کتک می‌خوریم، دوربین‌مون رو از دست می‌دیم. نگران نیستی؟ من واقعاً یه کم نگران این ویدیو هستم. به هر حال، باشه، اون نقش بادیگارد منو داره. اسم اینجا لونیک ناینه و بزرگ‌ترین زاغه کولی‌ها در اروپاست. بیاید ببینیمش، مردم جادویی.\"\n",
        "generate(example_api_key, example_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2ac8c5-a427-460e-d401-97328cda6366",
        "id": "7nzKlgOgk8nk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to: generated_audio_0.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_keys = [\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "jgKFetfagH8f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "# Load subtitles\n",
        "subs = pysrt.open('translated_Chernobyl_Zone.srt', encoding='utf-8')\n",
        "\n",
        "# Get total duration: the end time of the last subtitle\n",
        "last_end = subs[-1].end\n",
        "total_duration = (\n",
        "    last_end.hours * 3600 + last_end.minutes * 60 + last_end.seconds\n",
        ") * 1000 + last_end.milliseconds\n",
        "\n",
        "# Load from partial combined audio if exists\n",
        "partial_audio_path = 'combined_audio_partial.wav'\n",
        "if os.path.exists(partial_audio_path):\n",
        "    combined = AudioSegment.from_wav(partial_audio_path)\n",
        "    print(\"🔄 Loaded partial audio from previous run.\")\n",
        "else:\n",
        "    combined = AudioSegment.silent(duration=total_duration)\n",
        "    print(\"🎬 Starting new combined audio.\")\n",
        "\n",
        "# Read last completed index\n",
        "checkpoint_file = 'progress.txt'\n",
        "if os.path.exists(checkpoint_file):\n",
        "    with open(checkpoint_file, 'r') as f:\n",
        "        last_index = int(f.read().strip())\n",
        "else:\n",
        "    last_index = -1\n",
        "\n",
        "print(f\"🔁 Resuming from subtitle index {last_index + 1}\")\n",
        "\n",
        "for i, sub in enumerate(subs):\n",
        "    if i <= last_index:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Convert SRT times to milliseconds\n",
        "        start_time = (sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds) * 1000 + sub.start.milliseconds\n",
        "        end_time = (sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds) * 1000 + sub.end.milliseconds\n",
        "        time_window = end_time - start_time\n",
        "\n",
        "        input_text = sub.text\n",
        "        print(f\"🎤 Generating audio for subtitle {i}: {input_text}\")\n",
        "        n = i % len(api_keys)\n",
        "        generate(api_keys[n], input_text)\n",
        "        time.sleep(10)  # wait 10 seconds\n",
        "\n",
        "        chunk_path = f\"/content/chunk_{i+1}.wav\"\n",
        "        os.rename('/content/generated_audio_0.wav', chunk_path)\n",
        "\n",
        "        if not os.path.exists(chunk_path):\n",
        "            print(f\"❌ Warning: {chunk_path} not found, skipping.\")\n",
        "            continue\n",
        "\n",
        "        chunk = AudioSegment.from_wav(chunk_path)\n",
        "        duration_chunk = len(chunk)\n",
        "\n",
        "        #if duration_chunk > time_window:\n",
        "        print(f\"⚠️ Warning: {chunk_path} is too long by {(duration_chunk - time_window)/1000:.2f} seconds\")\n",
        "        temp_stretched = f\"chunk_stretched_{i+1}.wav\"\n",
        "        stretch_audio_to_fit(chunk_path, temp_stretched, time_window)\n",
        "        chunk = AudioSegment.from_wav(temp_stretched)\n",
        "\n",
        "        # Overlay the chunk at the correct position\n",
        "        combined = combined.overlay(chunk, position=start_time)\n",
        "\n",
        "        # ✅ Save checkpoint\n",
        "        with open(checkpoint_file, 'w') as f:\n",
        "            f.write(str(i))\n",
        "\n",
        "        # ✅ Save current audio progress\n",
        "        combined.export(partial_audio_path, format=\"wav\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error at subtitle {i}: {e}\")\n",
        "        print(f\"💥 Last completed index: {i-1}\")\n",
        "        print(f\"➡️ To resume from here, run this in a new cell:\")\n",
        "        print(f\"with open('progress.txt', 'w') as f:\\n    f.write('{i-1}')\")\n",
        "        break\n",
        "\n",
        "# ✅ Final export (optional overwrite of full audio)\n",
        "combined.export(\"combined_audio.wav\", format=\"wav\")\n",
        "print(\"✅ Final combined audio saved as 'combined_audio.wav'\")\n"
      ],
      "metadata": {
        "id": "yitop6dwT6he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXoUR1iLCjjz",
        "outputId": "3ecb3899-d658-4e99-ba01-f23e543cee3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/chunk_*.wav"
      ],
      "metadata": {
        "id": "2sSii0jL0DrE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy to google drive"
      ],
      "metadata": {
        "id": "ojA0za5bn4W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJXSuNSeNOA5",
        "outputId": "68e19aa4-943f-4e3f-fca8-ec6beabaa54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Paths for dubbed audio\n",
        "audio_source = \"/content/combined_audio.wav\"\n",
        "audio_destination = \"/content/drive/My Drive/dub/combined_audio.wav\"\n",
        "\n",
        "# Paths for translated subtitle\n",
        "srt_source = \"/content/translated.srt\"\n",
        "srt_destination = \"/content/drive/My Drive/dub/translated.srt\"\n",
        "\n",
        "def copy_file_if_exists(source, destination):\n",
        "    if not os.path.exists(source):\n",
        "        print(f\"❌ Source file does not exist: {source}\")\n",
        "        return\n",
        "    destination_dir = os.path.dirname(destination)\n",
        "    if not os.path.exists(destination_dir):\n",
        "        os.makedirs(destination_dir)\n",
        "        print(f\"📁 Created destination directory: {destination_dir}\")\n",
        "    shutil.copy(source, destination)\n",
        "    print(f\"✅ File copied to: {destination}\")\n",
        "\n",
        "# Copy files\n",
        "copy_file_if_exists(audio_source, audio_destination)\n",
        "copy_file_if_exists(srt_source, srt_destination)\n",
        "\n",
        "print(\"✅ All done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH6qKuFOqxeC",
        "outputId": "552679f0-05d0-4d2d-c66f-d591a10c6cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File copied to: /content/drive/My Drive/dub/combined_audio2.wav\n",
            "✅ All done.\n"
          ]
        }
      ]
    }
  ]
}