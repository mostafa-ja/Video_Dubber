{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdyipqESTVPxgWvAe0Upcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Video_Dubber/blob/main/TTS_Gemini_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sub"
      ],
      "metadata": {
        "id": "BH_qojhxSJC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download sub from https://downsub.com/"
      ],
      "metadata": {
        "id": "3fKH6I7MSUHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improveing sub"
      ],
      "metadata": {
        "id": "EdDd84SBQMuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BMjxhE2bJKz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871bf769-2766-48fd-e4bd-ba44315f5288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysrt\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/104.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m102.4/104.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from pysrt) (5.2.0)\n",
            "Building wheels for collected packages: pysrt\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=5f763226bfb108d755d604e2093b08e6b59eefb793790750938d847ea3c7a84d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/b2/df/ea10959920533975b4a74a25a35e6d79655b63f3006611a99f\n",
            "Successfully built pysrt\n",
            "Installing collected packages: pysrt\n",
            "Successfully installed pysrt-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pysrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "from datetime import timedelta\n",
        "\n",
        "def to_timedelta(srt_time):\n",
        "    return timedelta(\n",
        "        hours=srt_time.hours,\n",
        "        minutes=srt_time.minutes,\n",
        "        seconds=srt_time.seconds,\n",
        "        milliseconds=srt_time.milliseconds,\n",
        "    )\n",
        "\n",
        "def is_noise_line(text):\n",
        "    stripped = text.strip()\n",
        "    return stripped.startswith('[') and stripped.endswith(']')\n",
        "\n",
        "def merge_close_subtitles(subs, threshold_ms=100):\n",
        "    merged_subs = pysrt.SubRipFile()\n",
        "    i = 0\n",
        "    threshold = timedelta(milliseconds=threshold_ms)\n",
        "\n",
        "    # Remove \"[...]\" noise lines before merging\n",
        "    filtered_subs = [sub for sub in subs if not is_noise_line(sub.text)]\n",
        "\n",
        "    while i < len(filtered_subs):\n",
        "        current = filtered_subs[i]\n",
        "        text = current.text\n",
        "        start_time = current.start\n",
        "        end_time = current.end\n",
        "\n",
        "        while (\n",
        "            i + 1 < len(filtered_subs) and\n",
        "            to_timedelta(filtered_subs[i + 1].start) - to_timedelta(end_time) <= threshold\n",
        "        ):\n",
        "            i += 1\n",
        "            text += ' ' + filtered_subs[i].text\n",
        "            end_time = filtered_subs[i].end\n",
        "\n",
        "        # Only include if there are at least 4 words\n",
        "        if len(text.strip().split()) >= 4:\n",
        "            merged_subs.append(pysrt.SubRipItem(\n",
        "                index=len(merged_subs) + 1,\n",
        "                start=start_time,\n",
        "                end=end_time,\n",
        "                text=text.strip()\n",
        "            ))\n",
        "        i += 1\n",
        "\n",
        "    return merged_subs\n"
      ],
      "metadata": {
        "id": "DWWbkXGLJ-JE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "from datetime import timedelta\n",
        "\n",
        "def to_timedelta(srt_time):\n",
        "    return timedelta(\n",
        "        hours=srt_time.hours,\n",
        "        minutes=srt_time.minutes,\n",
        "        seconds=srt_time.seconds,\n",
        "        milliseconds=srt_time.milliseconds,\n",
        "    )\n",
        "\n",
        "def is_noise_line(text):\n",
        "    stripped = text.strip()\n",
        "    return stripped.startswith('[') and stripped.endswith(']')\n",
        "\n",
        "def merge_close_subtitles(subs, threshold_ms=100, max_duration_s=20):\n",
        "    merged_subs = pysrt.SubRipFile()\n",
        "    i = 0\n",
        "    threshold = timedelta(milliseconds=threshold_ms)\n",
        "    max_duration = timedelta(seconds=max_duration_s)\n",
        "\n",
        "    # Remove \"[...]\" noise lines before merging\n",
        "    filtered_subs = [sub for sub in subs if not is_noise_line(sub.text)]\n",
        "\n",
        "    while i < len(filtered_subs):\n",
        "        current = filtered_subs[i]\n",
        "        text = current.text\n",
        "        start_time = current.start\n",
        "        end_time = current.end\n",
        "        original_duration = to_timedelta(end_time) - to_timedelta(start_time)\n",
        "\n",
        "        j = i + 1\n",
        "        while j < len(filtered_subs):\n",
        "            next_sub = filtered_subs[j]\n",
        "            gap = to_timedelta(next_sub.start) - to_timedelta(end_time)\n",
        "            new_end_time = next_sub.end\n",
        "            merged_duration = to_timedelta(new_end_time) - to_timedelta(start_time)\n",
        "\n",
        "            if gap <= threshold and merged_duration <= max_duration and merged_duration <= original_duration + max_duration:\n",
        "                text += ' ' + next_sub.text\n",
        "                end_time = new_end_time\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # Only include if there are at least 3 words\n",
        "        if len(text.strip().split()) >= 3:\n",
        "            merged_subs.append(pysrt.SubRipItem(\n",
        "                index=len(merged_subs) + 1,\n",
        "                start=start_time,\n",
        "                end=end_time,\n",
        "                text=text.strip()\n",
        "            ))\n",
        "\n",
        "        i = j  # move to next non-merged subtitle\n",
        "\n",
        "    return merged_subs\n"
      ],
      "metadata": {
        "id": "fY57SsadIGR_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load subtitle from string\n",
        "subs = pysrt.from_string(\"\"\"1\n",
        "00:00:09,040 --> 00:00:10,240\n",
        "guys greetings\n",
        "\n",
        "2\n",
        "00:00:10,240 --> 00:00:13,440\n",
        "from slovakia listen everyone told us\n",
        "\n",
        "3\n",
        "00:00:13,440 --> 00:00:14,960\n",
        "not to come to this place\n",
        "\n",
        "4\n",
        "00:00:14,960 --> 00:00:17,039\n",
        "they said we get robbed we get beaten we\n",
        "\n",
        "5\n",
        "00:00:17,039 --> 00:00:18,560\n",
        "definitely lose our camera\n",
        "\n",
        "6\n",
        "00:00:18,560 --> 00:00:39,00\n",
        "[Music]\n",
        "\n",
        "7\n",
        "00:00:39,680 --> 00:00:43,440\n",
        "my money i'm getting mugged by seven\n",
        "\n",
        "8\n",
        "00:00:43,440 --> 00:00:44,399\n",
        "year olds\n",
        "\n",
        "9\n",
        "00:00:44,399 --> 00:00:46,960\n",
        "in 1970s there was a big gypsy village\n",
        "\n",
        "10\n",
        "00:00:46,960 --> 00:00:48,559\n",
        "here big romani village\n",
        "\n",
        "11\n",
        "00:01:04,000 --> 00:01:07,040\n",
        "well over time the local\n",
        "\n",
        "12\n",
        "00:01:07,040 --> 00:01:10,479\n",
        "slovakian people you could say moved out\n",
        "\n",
        "13\n",
        "00:01:10,479 --> 00:01:13,920\n",
        "and this is what became of lunic 9.\n",
        "\"\"\")\n",
        "\n",
        "# Merge with a 100ms gap tolerance\n",
        "merged_subs = merge_close_subtitles(subs, threshold_ms=100)\n"
      ],
      "metadata": {
        "id": "J-4JEF7nKbBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in merged_subs:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6_fbp1xKBOK",
        "outputId": "2e9fd7cc-e6d6-4147-bf6a-f5a7434162ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "00:00:09,040 --> 00:00:18,560\n",
            "guys greetings from slovakia listen everyone told us not to come to this place they said we get robbed we get beaten we definitely lose our camera\n",
            "\n",
            "2\n",
            "00:00:39,680 --> 00:00:48,559\n",
            "my money i'm getting mugged by seven year olds in 1970s there was a big gypsy village here big romani village\n",
            "\n",
            "3\n",
            "00:01:04,000 --> 00:01:13,920\n",
            "well over time the local slovakian people you could say moved out and this is what became of lunic 9.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_close_subtitles(subs, threshold_ms=100, max_duration_s=20)"
      ],
      "metadata": {
        "id": "16qKrdl_KsXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "\n",
        "# Load an existing .srt file\n",
        "subs = pysrt.open('Chernobyl_Zone.srt', encoding='utf-8')\n",
        "\n",
        "# Merge with a 100ms gap tolerance\n",
        "merged_subs = merge_close_subtitles(subs, threshold_ms=100, max_duration_s=15)\n",
        "\n",
        "# Save to a new file\n",
        "merged_subs.save('merged_Chernobyl_Zone.srt', encoding='utf-8')"
      ],
      "metadata": {
        "id": "Jht4Y4fXK_jP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "CN7KqbQwQSVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "translate by https://chatgpt.com/g/g-SVxuCE6HY-subtitle-translato or the below"
      ],
      "metadata": {
        "id": "fxnBkXGSSe7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gemini-srt-translator"
      ],
      "metadata": {
        "id": "RnbH-0IOQS1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gemini_srt_translator as gst\n",
        "\n",
        "gst.gemini_api_key = \"AIzaSyD-fWQVGebMwTXKo2efj8JnlC39IUaID5U\"\n",
        "gst.target_language = \"Persian\"\n",
        "gst.input_file = \"/content/merged_output (1).srt\"\n",
        "\n",
        "gst.translate()"
      ],
      "metadata": {
        "id": "w-mv57nHQUQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjoXG_5WSq6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text to speeach"
      ],
      "metadata": {
        "id": "m2XqYiWPkUCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stretch_audio_to_fit(input_wav, output_wav, target_duration_ms):\n",
        "    \"\"\"Adjusts audio speed using FFmpeg to match a target duration.\"\"\"\n",
        "    original = AudioSegment.from_wav(input_wav)\n",
        "    original_duration = len(original)\n",
        "    speed_factor = original_duration / target_duration_ms\n",
        "\n",
        "    # Clamp speed factor to range for quality\n",
        "    speed_factor = max(0.85, min(speed_factor, 1.5))\n",
        "\n",
        "    if abs(speed_factor - 1.0) < 0.01:\n",
        "        os.rename(input_wav, output_wav)\n",
        "        return\n",
        "\n",
        "    print(f\"â© Stretching audio: {input_wav} -> {output_wav} | Speed factor: {speed_factor:.2f}\")\n",
        "\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"ffmpeg\", \"-y\", \"-loglevel\", \"error\",\n",
        "                \"-i\", input_wav,\n",
        "                \"-filter:a\", f\"atempo={speed_factor}\",\n",
        "                output_wav\n",
        "            ],\n",
        "            check=True\n",
        "        )\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"âŒ FFmpeg failed while processing: {input_wav}\")"
      ],
      "metadata": {
        "id": "EvM1tcdU05ND"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To run this code you need to install the following dependencies:\n",
        "# pip install google-genai\n",
        "\n",
        "import base64\n",
        "import mimetypes\n",
        "import os\n",
        "import re\n",
        "import struct\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "def save_binary_file(file_name, data):\n",
        "    f = open(file_name, \"wb\")\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print(f\"File saved to: {file_name}\")\n",
        "\n",
        "\n",
        "def generate(api_key: str, text: str):\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    model = \"gemini-2.5-flash-preview-tts\"\n",
        "    #instruction = \"Read aloud in a warm, documentary-style tone, at a fast paceâ€”faster than normal speechâ€”while keeping clarity and expression: \\n\\n\"\n",
        "    instruction = \"Read aloud in a warm, documentary-style tone, slightly faster than a natural paceâ€”while keeping clarity and expression: \\n\\n\"\n",
        "    full_text = instruction + text\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=full_text),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        response_modalities=[\"audio\"],\n",
        "        speech_config=types.SpeechConfig(\n",
        "            voice_config=types.VoiceConfig(\n",
        "                prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "                    voice_name=\"Charon\"\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    file_index = 0\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        if (\n",
        "            chunk.candidates is None\n",
        "            or chunk.candidates[0].content is None\n",
        "            or chunk.candidates[0].content.parts is None\n",
        "        ):\n",
        "            continue\n",
        "        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
        "            file_name = f\"generated_audio_{file_index}\"\n",
        "            file_index += 1\n",
        "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
        "            data_buffer = inline_data.data\n",
        "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
        "            if file_extension is None:\n",
        "                file_extension = \".wav\"\n",
        "                data_buffer = convert_to_wav(inline_data.data, inline_data.mime_type)\n",
        "            save_binary_file(f\"{file_name}{file_extension}\", data_buffer)\n",
        "        else:\n",
        "            print(chunk.text)\n",
        "\n",
        "\n",
        "def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:\n",
        "    parameters = parse_audio_mime_type(mime_type)\n",
        "    bits_per_sample = parameters[\"bits_per_sample\"]\n",
        "    sample_rate = parameters[\"rate\"]\n",
        "    num_channels = 1\n",
        "    data_size = len(audio_data)\n",
        "    bytes_per_sample = bits_per_sample // 8\n",
        "    block_align = num_channels * bytes_per_sample\n",
        "    byte_rate = sample_rate * block_align\n",
        "    chunk_size = 36 + data_size\n",
        "\n",
        "    header = struct.pack(\n",
        "        \"<4sI4s4sIHHIIHH4sI\",\n",
        "        b\"RIFF\", chunk_size, b\"WAVE\", b\"fmt \", 16, 1, num_channels,\n",
        "        sample_rate, byte_rate, block_align, bits_per_sample, b\"data\", data_size\n",
        "    )\n",
        "    return header + audio_data\n",
        "\n",
        "\n",
        "def parse_audio_mime_type(mime_type: str) -> dict[str, int | None]:\n",
        "    bits_per_sample = 16\n",
        "    rate = 24000\n",
        "\n",
        "    parts = mime_type.split(\";\")\n",
        "    for param in parts:\n",
        "        param = param.strip()\n",
        "        if param.lower().startswith(\"rate=\"):\n",
        "            try:\n",
        "                rate_str = param.split(\"=\", 1)[1]\n",
        "                rate = int(rate_str)\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "        elif param.startswith(\"audio/L\"):\n",
        "            try:\n",
        "                bits_per_sample = int(param.split(\"L\", 1)[1])\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "    return {\"bits_per_sample\": bits_per_sample, \"rate\": rate}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VP5N-VGqkC3B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_api_key = \"\"\n",
        "example_text = \"Ø³Ù„Ø§Ù… Ø¨Ú†Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø§Ø³Ù„ÙˆØ§Ú©ÛŒ Ø¨Ù‡ØªÙˆÙ† Ø³Ù„Ø§Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù…. Ø¨Ø¨ÛŒÙ†ÛŒØ¯ØŒ Ù‡Ù…Ù‡ Ø¨Ù‡Ù…ÙˆÙ† Ú¯ÙØªÙ† Ù†ÛŒØ§ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§. Ú¯ÙØªÙ† Ø§ÛŒÙ†Ø¬Ø§ Ø¯Ø²Ø¯ÛŒÙ‡ØŒ Ú©ØªÚ© Ù…ÛŒâ€ŒØ®ÙˆØ±ÛŒÙ…ØŒ Ø¯ÙˆØ±Ø¨ÛŒÙ†â€ŒÙ…ÙˆÙ† Ø±Ùˆ Ø§Ø² Ø¯Ø³Øª Ù…ÛŒâ€ŒØ¯ÛŒÙ…. Ù†Ú¯Ø±Ø§Ù† Ù†ÛŒØ³ØªÛŒØŸ Ù…Ù† ÙˆØ§Ù‚Ø¹Ø§Ù‹ ÛŒÙ‡ Ú©Ù… Ù†Ú¯Ø±Ø§Ù† Ø§ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ Ù‡Ø³ØªÙ…. Ø¨Ù‡ Ù‡Ø± Ø­Ø§Ù„ØŒ Ø¨Ø§Ø´Ù‡ØŒ Ø§ÙˆÙ† Ù†Ù‚Ø´ Ø¨Ø§Ø¯ÛŒÚ¯Ø§Ø±Ø¯ Ù…Ù†Ùˆ Ø¯Ø§Ø±Ù‡. Ø§Ø³Ù… Ø§ÛŒÙ†Ø¬Ø§ Ù„ÙˆÙ†ÛŒÚ© Ù†Ø§ÛŒÙ†Ù‡ Ùˆ Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† Ø²Ø§ØºÙ‡ Ú©ÙˆÙ„ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø±ÙˆÙ¾Ø§Ø³Øª. Ø¨ÛŒØ§ÛŒØ¯ Ø¨Ø¨ÛŒÙ†ÛŒÙ…Ø´ØŒ Ù…Ø±Ø¯Ù… Ø¬Ø§Ø¯ÙˆÛŒÛŒ.\"\n",
        "generate(example_api_key, example_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2ac8c5-a427-460e-d401-97328cda6366",
        "id": "7nzKlgOgk8nk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to: generated_audio_0.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_keys = [\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "jgKFetfagH8f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "# Load subtitles\n",
        "subs = pysrt.open('translated_Chernobyl_Zone.srt', encoding='utf-8')\n",
        "\n",
        "# Get total duration: the end time of the last subtitle\n",
        "last_end = subs[-1].end\n",
        "total_duration = (\n",
        "    last_end.hours * 3600 + last_end.minutes * 60 + last_end.seconds\n",
        ") * 1000 + last_end.milliseconds\n",
        "\n",
        "# Load from partial combined audio if exists\n",
        "partial_audio_path = 'combined_audio_partial.wav'\n",
        "if os.path.exists(partial_audio_path):\n",
        "    combined = AudioSegment.from_wav(partial_audio_path)\n",
        "    print(\"ğŸ”„ Loaded partial audio from previous run.\")\n",
        "else:\n",
        "    combined = AudioSegment.silent(duration=total_duration)\n",
        "    print(\"ğŸ¬ Starting new combined audio.\")\n",
        "\n",
        "# Read last completed index\n",
        "checkpoint_file = 'progress.txt'\n",
        "if os.path.exists(checkpoint_file):\n",
        "    with open(checkpoint_file, 'r') as f:\n",
        "        last_index = int(f.read().strip())\n",
        "else:\n",
        "    last_index = -1\n",
        "\n",
        "print(f\"ğŸ” Resuming from subtitle index {last_index + 1}\")\n",
        "\n",
        "for i, sub in enumerate(subs):\n",
        "    if i <= last_index:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Convert SRT times to milliseconds\n",
        "        start_time = (sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds) * 1000 + sub.start.milliseconds\n",
        "        end_time = (sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds) * 1000 + sub.end.milliseconds\n",
        "        time_window = end_time - start_time\n",
        "\n",
        "        input_text = sub.text\n",
        "        print(f\"ğŸ¤ Generating audio for subtitle {i}: {input_text}\")\n",
        "        n = i % len(api_keys)\n",
        "        generate(api_keys[n], input_text)\n",
        "        time.sleep(10)  # wait 10 seconds\n",
        "\n",
        "        chunk_path = f\"/content/chunk_{i+1}.wav\"\n",
        "        os.rename('/content/generated_audio_0.wav', chunk_path)\n",
        "\n",
        "        if not os.path.exists(chunk_path):\n",
        "            print(f\"âŒ Warning: {chunk_path} not found, skipping.\")\n",
        "            continue\n",
        "\n",
        "        chunk = AudioSegment.from_wav(chunk_path)\n",
        "        duration_chunk = len(chunk)\n",
        "\n",
        "        #if duration_chunk > time_window:\n",
        "        print(f\"âš ï¸ Warning: {chunk_path} is too long by {(duration_chunk - time_window)/1000:.2f} seconds\")\n",
        "        temp_stretched = f\"chunk_stretched_{i+1}.wav\"\n",
        "        stretch_audio_to_fit(chunk_path, temp_stretched, time_window)\n",
        "        chunk = AudioSegment.from_wav(temp_stretched)\n",
        "\n",
        "        # Overlay the chunk at the correct position\n",
        "        combined = combined.overlay(chunk, position=start_time)\n",
        "\n",
        "        # âœ… Save checkpoint\n",
        "        with open(checkpoint_file, 'w') as f:\n",
        "            f.write(str(i))\n",
        "\n",
        "        # âœ… Save current audio progress\n",
        "        combined.export(partial_audio_path, format=\"wav\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error at subtitle {i}: {e}\")\n",
        "        print(f\"ğŸ’¥ Last completed index: {i-1}\")\n",
        "        print(f\"â¡ï¸ To resume from here, run this in a new cell:\")\n",
        "        print(f\"with open('progress.txt', 'w') as f:\\n    f.write('{i-1}')\")\n",
        "        break\n",
        "\n",
        "# âœ… Final export (optional overwrite of full audio)\n",
        "combined.export(\"combined_audio.wav\", format=\"wav\")\n",
        "print(\"âœ… Final combined audio saved as 'combined_audio.wav'\")\n"
      ],
      "metadata": {
        "id": "yitop6dwT6he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXoUR1iLCjjz",
        "outputId": "3ecb3899-d658-4e99-ba01-f23e543cee3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/chunk_*.wav"
      ],
      "metadata": {
        "id": "2sSii0jL0DrE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy to google drive"
      ],
      "metadata": {
        "id": "ojA0za5bn4W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJXSuNSeNOA5",
        "outputId": "68e19aa4-943f-4e3f-fca8-ec6beabaa54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Paths for dubbed audio\n",
        "audio_source = \"/content/combined_audio.wav\"\n",
        "audio_destination = \"/content/drive/My Drive/dub/combined_audio.wav\"\n",
        "\n",
        "# Paths for translated subtitle\n",
        "srt_source = \"/content/translated.srt\"\n",
        "srt_destination = \"/content/drive/My Drive/dub/translated.srt\"\n",
        "\n",
        "def copy_file_if_exists(source, destination):\n",
        "    if not os.path.exists(source):\n",
        "        print(f\"âŒ Source file does not exist: {source}\")\n",
        "        return\n",
        "    destination_dir = os.path.dirname(destination)\n",
        "    if not os.path.exists(destination_dir):\n",
        "        os.makedirs(destination_dir)\n",
        "        print(f\"ğŸ“ Created destination directory: {destination_dir}\")\n",
        "    shutil.copy(source, destination)\n",
        "    print(f\"âœ… File copied to: {destination}\")\n",
        "\n",
        "# Copy files\n",
        "copy_file_if_exists(audio_source, audio_destination)\n",
        "copy_file_if_exists(srt_source, srt_destination)\n",
        "\n",
        "print(\"âœ… All done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH6qKuFOqxeC",
        "outputId": "552679f0-05d0-4d2d-c66f-d591a10c6cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… File copied to: /content/drive/My Drive/dub/combined_audio2.wav\n",
            "âœ… All done.\n"
          ]
        }
      ]
    }
  ]
}